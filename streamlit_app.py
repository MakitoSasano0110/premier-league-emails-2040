import streamlit as st
import os
import glob
import re
from typing import List, Dict

# Configure page
st.set_page_config(
    page_title="âš½ Premier League Email Search",
    page_icon="âš½",
    layout="wide",
    initial_sidebar_state="expanded"
)

class EmailSearchApp:
    def __init__(self, emails_directory: str = "."):
        self.emails_directory = emails_directory
        self.emails_data = self.load_emails()
    
    @st.cache_data
    def load_emails(_self):
        """Load all email files and extract content"""
        emails_data = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Search for email files in subdirectories
        email_files = []
        for club in ["Arsenal", "Chelsea", "Liverpool"]:
            club_dir = os.path.join(_self.emails_directory, club)
            if os.path.exists(club_dir):
                email_files.extend(glob.glob(os.path.join(club_dir, "*.msg")))
        
        total_files = len(email_files)
        for i, file_path in enumerate(email_files):
            try:
                progress = (i + 1) / total_files
                progress_bar.progress(progress)
                status_text.text(f"Loading {os.path.basename(file_path)}... ({i+1}/{total_files})")
                
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                email_data = _self.parse_email_static(content, file_path)
                emails_data.append(email_data)
            except Exception as e:
                st.error(f"Error loading {file_path}: {e}")
        
        progress_bar.empty()
        status_text.empty()
        
        return emails_data
    
    @staticmethod
    def parse_email_static(content: str, file_path: str) -> Dict:
        """Parse email content and extract metadata"""
        lines = content.split('\n')
        
        email_data = {
            'file_path': file_path,
            'club': os.path.basename(os.path.dirname(file_path)),
            'filename': os.path.basename(file_path),
            'content': content,
            'from': '',
            'to': '',
            'subject': '',
            'date': '',
            'body': ''
        }
        
        # Extract header information
        body_start = 0
        for i, line in enumerate(lines):
            if line.startswith('From:'):
                email_data['from'] = line[5:].strip()
            elif line.startswith('To:'):
                email_data['to'] = line[3:].strip()
            elif line.startswith('Subject:'):
                email_data['subject'] = line[8:].strip()
            elif line.startswith('Date:'):
                email_data['date'] = line[5:].strip()
            elif line.strip() == '' and i > 3:
                body_start = i + 1
                break
        
        email_data['body'] = '\n'.join(lines[body_start:])
        return email_data
    
    def search_emails(self, query: str, top_k: int = 3) -> List[Dict]:
        """Simple keyword-based search"""
        query_words = query.lower().split()
        results = []
        
        for email in self.emails_data:
            content_lower = email['content'].lower()
            score = 0
            
            for word in query_words:
                if word in content_lower:
                    score += content_lower.count(word)
            
            if score > 0:
                email_copy = email.copy()
                email_copy['score'] = score
                results.append(email_copy)
        
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:top_k]
    
    def generate_answer(self, query: str, search_results: List[Dict]) -> str:
        """Generate answer based on search results"""
        if not search_results:
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€é–¢é€£ã™ã‚‹ãƒ¡ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        answer = ""
        
        for i, result in enumerate(search_results, 1):
            answer += f"**{i}. å‡ºå…¸: {result['club']}/{result['filename']}**\n"
            answer += f"ğŸ“§ ä»¶å: {result['subject']}\n"
            answer += f"ğŸ“… æ—¥ä»˜: {result['date']}\n"
            
            # Extract relevant information based on query
            if any(word in query.lower() for word in ['å¥‘ç´„', 'å¹´ä¿¸', 'salary', 'contract']):
                contract_info = self.extract_contract_info(result['body'])
                if contract_info:
                    answer += contract_info
            elif any(word in query.lower() for word in ['ç§»ç±', 'transfer']):
                transfer_info = self.extract_transfer_info(result['body'])
                if transfer_info:
                    answer += transfer_info
            else:
                # Show first few lines of content
                lines = result['body'].split('\n')[:5]
                answer += "ğŸ“„ å†…å®¹æŠœç²‹:\n"
                for line in lines:
                    if line.strip():
                        answer += f"  {line.strip()}\n"
            
            answer += "\n---\n\n"
        
        return answer
    
    def extract_contract_info(self, body: str) -> str:
        """Extract contract-related information"""
        info = "ğŸ’¼ å¥‘ç´„æƒ…å ±:\n"
        found_info = False
        
        # Extract salary information
        salary_patterns = [
            r'Â£([\d,]+)/week',
            r'Weekly Wage: Â£([\d,]+)',
            r'Base Salary: Â£([\d,]+) per week'
        ]
        
        for pattern in salary_patterns:
            match = re.search(pattern, body)
            if match:
                info += f"  ğŸ’° é€±çµ¦: Â£{match.group(1)}\n"
                found_info = True
                break
        
        # Extract contract duration
        duration_match = re.search(r'Duration: (\d+) years', body)
        if duration_match:
            info += f"  ğŸ“† å¥‘ç´„æœŸé–“: {duration_match.group(1)}å¹´\n"
            found_info = True
        
        # Extract appearances
        appearances_match = re.search(r'(\d+) appearances', body)
        if appearances_match:
            info += f"  âš½ å‡ºå ´è©¦åˆæ•°: {appearances_match.group(1)}è©¦åˆ\n"
            found_info = True
        
        # Extract goals
        goals_match = re.search(r'(\d+) goals', body)
        if goals_match:
            info += f"  ğŸ¥… ã‚´ãƒ¼ãƒ«æ•°: {goals_match.group(1)}ã‚´ãƒ¼ãƒ«\n"
            found_info = True
        
        # Extract assists
        assists_match = re.search(r'(\d+) assists', body)
        if assists_match:
            info += f"  ğŸ¯ ã‚¢ã‚·ã‚¹ãƒˆæ•°: {assists_match.group(1)}ã‚¢ã‚·ã‚¹ãƒˆ\n"
            found_info = True
        
        return info if found_info else ""
    
    def extract_transfer_info(self, body: str) -> str:
        """Extract transfer-related information"""
        info = "ğŸ”„ ç§»ç±æƒ…å ±:\n"
        found_info = False
        
        # Extract transfer fee
        fee_patterns = [
            r'Transfer Fee: Â£([\d,]+) million',
            r'Fee: Â£([\d,]+) million',
            r'â‚¬([\d,]+) million'
        ]
        
        for pattern in fee_patterns:
            match = re.search(pattern, body)
            if match:
                currency = "Â£" if "Â£" in pattern else "â‚¬"
                info += f"  ğŸ’µ ç§»ç±é‡‘: {currency}{match.group(1)} million\n"
                found_info = True
                break
        
        return info if found_info else ""

@st.cache_resource
def get_email_search_app():
    """Create and cache the EmailSearchApp instance"""
    return EmailSearchApp()

def main():
    # Header
    st.title("âš½ ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚° ãƒ¡ãƒ¼ãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("### 2040å¹´ã®ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚°ã‚¯ãƒ©ãƒ–ã®ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰é¸æ‰‹æƒ…å ±ã‚’æ¤œç´¢")
    
    # Initialize the app with caching
    with st.spinner("ğŸ“§ ãƒ¡ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        search_app = get_email_search_app()
    st.success(f"âœ… {len(search_app.emails_data)}é€šã®ãƒ¡ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    
    # Sidebar with information
    with st.sidebar:
        st.header("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        total_emails = len(search_app.emails_data)
        clubs = list(set([email['club'] for email in search_app.emails_data]))
        
        st.metric("ğŸ“§ ç·ãƒ¡ãƒ¼ãƒ«æ•°", total_emails)
        st.metric("ğŸŸï¸ å¯¾è±¡ã‚¯ãƒ©ãƒ–æ•°", len(clubs))
        
        st.subheader("ğŸ† å¯¾è±¡ã‚¯ãƒ©ãƒ–")
        for club in sorted(clubs):
            club_emails = len([e for e in search_app.emails_data if e['club'] == club])
            st.write(f"ğŸ”¸ **{club}**: {club_emails}é€š")
        
        st.markdown("---")
        st.subheader("ğŸ’¡ ä½¿ã„æ–¹ã®ãƒ’ãƒ³ãƒˆ")
        st.markdown("""
        - é¸æ‰‹åã¯è‹±èªã§å…¥åŠ›
        - è³ªå•ã¯æ—¥æœ¬èªOK
        - ã€Œå¥‘ç´„ã€ã€Œç§»ç±ã€ã€Œå¹´ä¿¸ã€ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
        """)
    
    # Sample questions
    st.subheader("ğŸ” ã‚µãƒ³ãƒ—ãƒ«è³ªå•")
    sample_questions = [
        "Mohamed Salah Jr.ã®å¥‘ç´„æ¡ä»¶ã¯ï¼Ÿ",
        "Gabriel Fernandez ç§»ç±é‡‘",
        "Arsenal contract salary", 
        "Chelsea transfer fee",
        "Kai Havertz Jr. transfer"
    ]
    
    cols = st.columns(len(sample_questions))
    for i, question in enumerate(sample_questions):
        if cols[i].button(f"ğŸ“ {question}", key=f"sample_{i}"):
            st.session_state.query_input = question
    
    # Main search interface
    st.markdown("---")
    st.subheader("ğŸ’¬ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    # Text input
    query = st.text_input(
        "è³ªå•:",
        value=st.session_state.get('query_input', ''),
        placeholder="ä¾‹: Mohamed Salah Jr.ã®å¥‘ç´„å†…å®¹ã‚’æ•™ãˆã¦",
        key="main_query"
    )
    
    # Clear the sample question from session state
    if 'query_input' in st.session_state:
        del st.session_state.query_input
    
    # Search button
    col1, col2, col3 = st.columns([1, 1, 4])
    search_clicked = col1.button("ğŸ” æ¤œç´¢", type="primary")
    clear_clicked = col2.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢")
    
    if clear_clicked:
        st.rerun()
    
    # Perform search
    if search_clicked and query:
        with st.spinner("ğŸ” æ¤œç´¢ä¸­..."):
            results = search_app.search_emails(query, top_k=3)
            
            if results:
                st.success(f"âœ… {len(results)}ä»¶ã®é–¢é€£ãƒ¡ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                
                # Generate and display answer
                answer = search_app.generate_answer(query, results)
                
                st.markdown("---")
                st.subheader("ğŸ“‹ æ¤œç´¢çµæœ")
                st.markdown(answer)
                
                # Show detailed email content in expandable sections
                st.markdown("---")
                st.subheader("ğŸ“§ è©³ç´°ãªãƒ¡ãƒ¼ãƒ«å†…å®¹")
                
                for i, result in enumerate(results, 1):
                    with st.expander(f"ğŸ“„ {i}. {result['club']} - {result['subject']} (ã‚¹ã‚³ã‚¢: {result['score']})"):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write(f"**é€ä¿¡è€…:** {result['from']}")
                            st.write(f"**å®›å…ˆ:** {result['to']}")
                        
                        with col2:
                            st.write(f"**æ—¥ä»˜:** {result['date']}")
                            st.write(f"**ã‚¯ãƒ©ãƒ–:** {result['club']}")
                        
                        st.markdown("**å†…å®¹:**")
                        st.text(result['body'])
            else:
                st.warning("âŒ é–¢é€£ã™ã‚‹ãƒ¡ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
    
    elif search_clicked and not query:
        st.error("âš ï¸ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray;'>
    ğŸ† Premier League Email Search System 2040 | 
    Built with Streamlit | 
    ğŸ“§ 30 emails from Arsenal, Chelsea, Liverpool
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()